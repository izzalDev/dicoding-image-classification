# -*- coding: utf-8 -*-
"""Copy of rizal_4.ipynb(3class)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RGDiWY46NfFPXjBQBpcLYIgJMn9rAqEC

# NAMA : RIZAL FADLULLAH<br>
# EMAIL : rizal.fadlullah@gmail.com
"""

!wget -q --show-progress --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1gVlyNFK6Nx5zJZc1nEdjU7vg0SaEUJOm' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=1gVlyNFK6Nx5zJZc1nEdjU7vg0SaEUJOm" -O dataset.zip && rm -rf /tmp/cookies.txt
!unzip -qq -o dataset.zip
!pip install livelossplot -q --quiet

import os
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files
import os
import pathlib

img_height = 150
img_width = 150
batch_size = 20

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
  rescale=1./255,
  rotation_range=90,
  horizontal_flip=True, 
  vertical_flip=True,
  validation_split=0.2)

train_generator = datagen.flow_from_directory(
    "dataset/",
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode="categorical",
    subset="training",
    shuffle=True,
)
val_generator = datagen.flow_from_directory(
    "dataset/",
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation",
    shuffle=True,
)

model = tf.keras.models.Sequential([
    tf.keras.applications.ResNet152V2(weights="imagenet", include_top=False, input_tensor=tf.keras.layers.Input(shape=(img_width, img_height, 3))),
    tf.keras.layers.MaxPool2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(2048, activation='relu'),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.summary()

opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_loss')<0.20):
      print("\nLoss telah mencapai < 0.2")
      self.model.stop_training = True
callbacks = myCallback()

history = model.fit(
  train_generator,
  epochs=200,
  validation_data=val_generator,
  validation_steps=4,
  callbacks=[callbacks]
)

test_loss, test_acc = model.evaluate(train_generator)
print ('\nTest accuracy:', test_acc)

#@title Train & Validation Plot
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))
fig.suptitle('Train & Validation Plot')
ax1.set_title('Accuracy')
ax1.plot(history.history['accuracy'])
ax1.plot(history.history['val_accuracy'])
ax1.set_ylabel('accuracy')
ax1.set_xlabel('epoch')
ax1.legend(['train', 'val'], loc='upper left')
ax2.set_title('loss')
ax2.plot(history.history['loss'])
ax2.plot(history.history['val_loss'])
ax2.legend(['train', 'val'], loc='upper left')
ax2.set_ylabel('loss')
ax2.set_xlabel('epoch')
plt.show()

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
 
tflite_model_file = pathlib.Path('fastfood_classification.tflite')
tflite_model_file.write_bytes(tflite_model)